import tensorflow as tf
import numpy as np
#numpy 라이브러리를 np라는 이름으로 반입
tf.enable_eager_execution()
#그래프 기반 모드에서 즉시 실행 (Eager Execution) 모드로 변경
tf.__version__
#텐서플로우 버젼 확인

tf.set_random_seed(0)
#seed가 같으면 이후의 랜덤하게 생성되는 숫자들이 동일하게 만들어짐. 
x1_data = [1, 0, 3, 0, 5]
x2_data = [0, 2, 0, 4, 0]
y_data  = [1, 2, 3, 4, 5]
#데이터 입력

W1 = tf.Variable(tf.random_uniform([1], -10.0, 10.0))
W2 = tf.Variable(tf.random_uniform([1], -10.0, 10.0))
b  = tf.Variable(tf.random_uniform([1], -10.0, 10.0))
#W1와 W2와 b에 -10 부터 10 까지 랜덤한 값을 주겠다

learning_rate = tf.Variable(0.001)
#학습률 입력

for i in range(1000+1):
    with tf.GradientTape() as tape:
    #tape에 계산 과정을 기록해두었다가 tape.gradient를 이용해서 미분을 자동으로 구할 수 있음
        hypothesis = W1 * x1_data + W2 * x2_data + b
        cost = tf.reduce_mean(tf.square(hypothesis - y_data))
        #hypothesis 와 cost 함수 정의
    W1_grad, W2_grad, b_grad = tape.gradient(cost, [W1, W2, b])
    #경사를 계산하기 위해서 테이프를 뒤로 감아서 재생 , 단하나의 경사만 계산 
    W1.assign_sub(learning_rate * W1_grad)
    W2.assign_sub(learning_rate * W2_grad)
    b.assign_sub(learning_rate * b_grad)

    if i % 50 == 0:
        print("{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.6f}".format(
          i, cost.numpy(), W1.numpy()[0], W2.numpy()[0], b.numpy()[0]))

x_data = [
    [1., 0., 3., 0., 5.],
    [0., 2., 0., 4., 0.]
]
#x_data 값 입력
y_data  = [1, 2, 3, 4, 5]
#y_data 값 입력

W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0))
b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))
#난수 W와 b 생성

learning_rate = tf.Variable(0.001)
#학습률 입력

for i in range(1000+1):
    with tf.GradientTape() as tape:
        hypothesis = tf.matmul(W, x_data) + b # (1, 2) * (2, 5) = (1, 5)
        cost = tf.reduce_mean(tf.square(hypothesis - y_data))
        #손실 함수를 작성
        W_grad, b_grad = tape.gradient(cost, [W, b])
        W.assign_sub(learning_rate * W_grad)
        b.assign_sub(learning_rate * b_grad)
    
    if i % 50 == 0:
        print("{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.6f}".format(
            i, cost.numpy(), W.numpy()[0][0], W.numpy()[0][1], b.numpy()[0]))

import tensorflow as tf
x_data = [
    [1., 1., 1., 1., 1.], # bias(b)
    [1., 0., 3., 0., 5.], 
    [0., 2., 0., 4., 0.]
]
y_data  = [1, 2, 3, 4, 5]
#x_data 와 y_data 입력

W = tf.Variable(tf.random_uniform([1, 3], -1.0, 1.0)) 
#가중치 변수 W는 [입력층,출력층]의 구성임
learning_rate = 0.001
#학습률 설정
optimizer = tf.train.GradientDescentOptimizer(learning_rate)
# 미분을 통해 최저 비용을 향해 진행하도록 만드는 핵심 함수 이때 rate를 전달했기 때문에 매번 learning_rate 만큼 감소
for i in range(1000+1):
    with tf.GradientTape() as tape:
        hypothesis = tf.matmul(W, x_data)
        cost = tf.reduce_mean(tf.square(hypothesis - y_data))

    grads = tape.gradient(cost, [W])
    optimizer.apply_gradients(grads_and_vars=zip(grads,[W]))
    if i % 50 == 0:
        print("{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.4f}".format(
            i, cost.numpy(), W.numpy()[0][0], W.numpy()[0][1], W.numpy()[0][2]))

X = tf.constant([[1., 2.], 
                 [3., 4.]])
y = tf.constant([[1.5], [3.5]])

W = tf.Variable(tf.random_normal([2, 1]))
b = tf.Variable(tf.random_normal([1]))


optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)
# 미분을 통해 최저 비용을 향해 진행하도록 만드는 핵심 함수 이때 rate를 전달했기 때문에 매번 0.01만큼씩 내려가게 됨
n_epoch = 1000+1
#n_epoch 값 정의
print("epoch | cost")
#출력
for i in range(n_epoch):
    with tf.GradientTape() as tape:
     #tf.GradientTape() 는 cost 함수의 gradient를 기록할때 사용함
        y_pred = tf.matmul(X, W) + b
        cost = tf.reduce_mean(tf.square(y_pred - y))
         #cost 함수 정의
    
    optimizer.apply_gradients(grads_and_vars=zip(grads, [W, b]))
    if i % 50 == 0:
        print("{:5} | {:10.6f}".format(i, cost.numpy()))

tf.set_random_seed(0)

x1 = [ 73.,  93.,  89.,  96.,  73.]
x2 = [ 80.,  88.,  91.,  98.,  66.]
x3 = [ 75.,  93.,  90., 100.,  70.]
Y  = [152., 185., 180., 196., 142.]
#x1, x2, x3 값 지정

w1 = tf.Variable(10.)
w2 = tf.Variable(10.)
w3 = tf.Variable(10.)
b  = tf.Variable(10.)
#네개의 변수값 생성
learning_rate = 0.000001
#학습률 설정


for i in range(1000+1):
    #
    with tf.GradientTape() as tape:
    #tape에 계산 과정을 기록해두었다가 tape.gradient를 이용해서 미분을 자동으로 구할 수 있음
        hypothesis = w1 * x1 +  w2 * x2 + w3 * x3 + b
        cost = tf.reduce_mean(tf.square(hypothesis - Y))
    # cost 함수 계산
    # Cost Function 은 최소제곱법을 따라 정의하되, Tensorflow에서 제공하는 함수를 적절히 활용
    w1_grad, w2_grad, w3_grad, b_grad = tape.gradient(cost, [w1, w2, w3, b])
    
    
    w1.assign_sub(learning_rate * w1_grad)
    w2.assign_sub(learning_rate * w2_grad)
    w3.assign_sub(learning_rate * w3_grad)
    b.assign_sub(learning_rate * b_grad)
    #w1,w2,w3 와 b의 값을 업데이트
    if i % 50 == 0:
      print("{:5} | {:12.4f}".format(i, cost.numpy()))

